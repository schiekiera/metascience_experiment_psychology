# Metascience experiment history

This repository contains anonymized data for a metascientific experiment on the influence of publication bias on psychologists' assessments of clinical psychology abstracts.

## Abstract
### Background: Publishing all study results, including non-significant and hypothesis-inconsistent findings, is central to the process of scientific knowledge production. Yet, review studies suggest that results that are statistically significant or consistent with hypotheses are preferred in the publication process and in reception. However, questions remain about the mechanisms underlying publication bias, and work has focused on between-subjects designs rather than within-subjects experiments. Using an experimental within-subject design, we investigated decision-making processes based on Dual Process Theories to understand selective (non-)publication and (non-)reception. Specifically, we examined (1) intuitive and (2) considered evaluations of research abstracts, along with the accompanying (3) Feeling of Rightness (FOR) of intuitive evaluations, as functions of the experimental variation of statistical significance and hypothesis-consistency. 
### Methods: In each of four online experiments (each n = 75), 16 fictitious research paper abstracts were randomly presented to a sample of clinical psychology researchers. Participants were first asked for the likelihood of submitting the paper for publication, reading the paper, or citing the paper based solely on the abstract, providing a fast and intuitive evaluation. They were then asked to rate the certainty of this response (FOR), and finally, they were prompted to rethink the decision and provide a more considered evaluation. For each experiment we fitted multilevel and multilevel mediation models to investigate whether (1) intuitive evaluations are associated with the treatment variable or (2a) whether response changes between considered and intuitive evaluations are mediated by FOR and (2b) directly associated with the treatment variable.
